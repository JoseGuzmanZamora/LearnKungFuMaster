{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Framework con los algoritmos de ML necesarios \n",
    "import tensorflow as tf \n",
    "import keras\n",
    "\n",
    "# Funciones necesarias para la arquitectura de la CNN \n",
    "from keras.utils import plot_model, to_categorical\n",
    "from keras.models import Sequential, load_model, Model\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "\n",
    "import gym\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "import numpy as np \n",
    "import pickle\n",
    "\n",
    "from collections import deque\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discrete(14)\n",
      "Box(210, 160, 3)\n",
      "(210, 160, 3)\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('KungFuMaster-v0')\n",
    "\n",
    "print(env.action_space)\n",
    "# Discrete 14 posibilidades\n",
    "actions = env.action_space.n\n",
    "\n",
    "print(env.observation_space)\n",
    "# una imagen de 210,160,3 shape\n",
    "dimensions = env.observation_space.shape\n",
    "print(dimensions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelo(dimensions):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(32, (3,3), activation='relu', input_shape=dimensions))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(Conv2D(64, (3,3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64,activation='relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(64,activation='relu'))\n",
    "    \n",
    "    model.add(Dense(actions,activation='linear'))\n",
    "    \n",
    "    opt = keras.optimizers.RMSprop(learning_rate=0.0001)\n",
    "    model.compile(optimizer=opt,\n",
    "                  loss='mse',\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# originalmente estaba modelo_principal.predict, ahorita vamos a ver \n",
    "def predecir_qs(img,modelo):\n",
    "    return np.argmax(modelo.predict(np.expand_dims(img,0) / 255))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# en base a este contador vamos a saber cuando actualizar los pesos del modelo predictivo\n",
    "# es decir cada vez que llega a este limite se va a actualizar el modelo de target \n",
    "# cada 5 partidas se va a actualizar \n",
    "actualizacion_limit = 7\n",
    "# batch size \n",
    "batch_s = 32 \n",
    "# este valor indica que tanto se aprecian los valores futuros en relacion a los presentes\n",
    "# si el valor es 1 significa que los valores futuros tienen la misma importancia \n",
    "descuento = 0.99\n",
    "\n",
    "# codigo del entrenamiento, al momento de llegar aqui, venimos del loop principal y lo que ha pasado hasta el \n",
    "# momento es que se hizo un step y la informacion de ese step se agrego a la memoria, ahora hay que entrenar \n",
    "# dependiendo de la cantidad de valores que hay disponibles.\n",
    "def train(done_test,actualizacion,save):\n",
    "    \n",
    "    # este es el caso en el que no tenemos suficientes datos para obtener de la memoria.\n",
    "    if len(memory) < batch_s:\n",
    "        return actualizacion\n",
    "    \n",
    "    # obtener el batch que se va a usar de entrenamiento, este se obtiene de manera aleatoria de la memoria \n",
    "    batch = random.sample(memory, batch_s)\n",
    "    \n",
    "    # obtener imagenes anteriores, estas provienen de la memoria, es decir tendriamos 64 imagenes, se estandarizan\n",
    "    imagenes_anteriores = np.array([i[0] for i in batch]) / 255\n",
    "    # los valores de q correspondientes a la parte de la derecha de la ecuacion \n",
    "    # lo que hace esto es Q(s,t) en donde s es la imagen actual o pasdas en este caso \n",
    "    # a esto tambien se le conoce como los valores de y_pred, el resultado de nuestra prediccion obviamente \n",
    "    calidades_actuales = modelo_prediccion.predict(imagenes_anteriores)\n",
    "    \n",
    "    # estas son las imagenes nuevas pero igual de cada uno de los elementos del batch \n",
    "    imagenes_nuevas = np.array([i[3] for i in batch]) / 255\n",
    "    # esto corresponde a la parte izquierda de la formula es decir Q(s',t') son las imagenes futuras y se obtiene su calidad\n",
    "    # sin embargo en este caso tenemos que usar el modelo target porque es el que se va actualizando\n",
    "    calidades_futuras = modelo_target.predict(imagenes_nuevas)\n",
    "    \n",
    "    # iniciar los arreglos que van a tener toda la info para el entrenamiento temporal de la red \n",
    "    # x tiene que llevar todas las imagenes anteriores o actuales \n",
    "    x = []\n",
    "    # y tiene que llevar todos los resultados del modelo de target pero junto con el resto de la formula reward + decay * Q'\n",
    "    y = []\n",
    "    \n",
    "    # este loop todavia no es de entrenamiento, solo es de poblar el dataset temporal que es del tamanio del batch\n",
    "    # toda la info que hay en el enumerate es lo que guardamos anteriormente en la memoria \n",
    "    for index, (imagen_actual, action, reward, imagen_nueva, done) in enumerate(batch):\n",
    "        # si por alguna razon obtenemos un done del batch hay que considerar que hacer \n",
    "        if not done:\n",
    "            # si no esta done entonces el valor del target se evalua en base a la formula\n",
    "            valor_nuevo = reward + (descuento * np.max(calidades_futuras[index]))\n",
    "        else:\n",
    "            # de lo contrario no va haber imagen futura entonces el reward es el mismo que el valor \n",
    "            valor_nuevo = reward \n",
    "        \n",
    "        # obtener las calidades correspondientes al step actual, seria un listado de resultados anteriores \n",
    "        # cada uno de estos listados va a tener un listado de la cantidad de acciones que hay 14 para kung fu \n",
    "        calidades_actuales_temp = calidades_actuales[index]\n",
    "        # ya que tenemos las calidades temporales pues obviamente hay que actualizar la de la accion que se tomo\n",
    "        # por lo tanto en action cambia al valor nuevo que se utilizo \n",
    "        calidades_actuales_temp[action] = valor_nuevo\n",
    "        \n",
    "        # agregar la imagen actual de cada estado del batch a x igual con su normalizacion \n",
    "        x.append(imagen_actual / 255)\n",
    "        # agregar las calidades de esa imagen, la diferencia es que como esto es el target \n",
    "        # aunque diga actuales sabemos que la accion de esta se cambio en base a las calidades del futuro\n",
    "        y.append(calidades_actuales_temp)\n",
    "        \n",
    "    # entrenar el modelo en base a lo que acabamos de poblar en el dataset temporal \n",
    "    # lo vamos a entrenar cada vez que termina una partida si no estariamos entrenandolo demasiadas veces cada 32 steps \n",
    "    modelo_prediccion.fit(np.asarray(x), np.asarray(y), batch_size=batch_s,\n",
    "                         verbose = 0, shuffle=False if done_test else None)\n",
    "    # verificar si si realizo el entrenamiento o no \n",
    "    if done_test:\n",
    "        # aqui entra si logro entrenar, es decir que termino el juego\n",
    "        actualizacion += 1\n",
    "        if actualizacion > actualizacion_limit:\n",
    "            # en este caso ya nos tocaria actualizar el modelo que hace las predicciones\n",
    "            actualizacion = 0\n",
    "            modelo_target.set_weights(modelo_prediccion.get_weights())\n",
    "    return actualizacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv.resize(img,(64,64))[30:50,5:]\n",
    "# dimensiones seleccionadas para la parte interesante del juego. \n",
    "adhoc_dims = (20,59,1)\n",
    "\n",
    "# este va a ser el modelo que debe de hacer el fit, es decir entrenamiento\n",
    "modelo_prediccion = modelo(adhoc_dims)\n",
    "# este modelo va a ser el que se va actualizar despues de cierta cantidad de iteraciones y hace el predict \n",
    "modelo_target = modelo(adhoc_dims)\n",
    "# los pesos tienen que empezar igual \n",
    "modelo_target.set_weights(modelo_prediccion.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor modelo guardado en partida # 4000\n",
      "Episodio # 4000\n",
      "Mejor modelo guardado en partida # 4001\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-39e4cb490824>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     59\u001b[0m         \u001b[0mmemory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimagen_actual\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimagen_nueva\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m         \u001b[1;31m# ENTRENAMIENTO, actualizacion es un contador de actualizacion del modelo de target\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m         \u001b[0mactualizacion\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mactualizacion\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[1;31m# actualizar la imagen con la nueva que devuelve el step\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-ac68e19e6579>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(done_test, actualizacion, save)\u001b[0m\n\u001b[0;32m     67\u001b[0m     \u001b[1;31m# lo vamos a entrenar cada vez que termina una partida si no estariamos entrenandolo demasiadas veces cada 32 steps\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m     modelo_prediccion.fit(np.asarray(x), np.asarray(y), batch_size=batch_s,\n\u001b[1;32m---> 69\u001b[1;33m                          verbose = 0, shuffle=False if done_test else None)\n\u001b[0m\u001b[0;32m     70\u001b[0m     \u001b[1;31m# verificar si si realizo el entrenamiento o no\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdone_test\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\cs7\\env\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1239\u001b[1;33m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[0;32m   1240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[1;32md:\\cs7\\env\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[0;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\cs7\\env\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3725\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3726\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3727\u001b[1;33m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3728\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3729\u001b[0m     \u001b[1;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\cs7\\env\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1549\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1550\u001b[0m     \"\"\"\n\u001b[1;32m-> 1551\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1552\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1553\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\cs7\\env\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1589\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[0;32m   1590\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[1;32m-> 1591\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1592\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1593\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\cs7\\env\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1690\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1692\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\cs7\\env\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32md:\\cs7\\env\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Se obtendra una muestra aleatorea de la cantidad de steps y estos se convierten en un batch que se va a entrenar con el modelo principal\n",
    "\n",
    "# inicializacion de la memoria de iteraciones anteriores, el modelo \n",
    "# principal se va a ir entrenando por medio de mini batches que provienen de una \n",
    "# muestra aleatoria de la memoria. la cantidad de valores maximo es 20k\n",
    "memory = deque(maxlen=50000)\n",
    "# el minimo de valores permitido en la memoria para que se comience hacer el muestreo aleatorio\n",
    "minimo_memoria = 1000\n",
    "# cantidad de partidas que el ambiente va a utilizar para realizar el entrenamiento \n",
    "episodios = 25000\n",
    "# punto de decision para explorar o explotar, si el valor es mayor a epsilon entonces \n",
    "# exploto mi modelo, de lo contrario exploro nuevos movimientos con una funcion random. \n",
    "epsilon = 1\n",
    "# la cantidad que epsilon va a ir decrementando con el tiempo. \n",
    "decay = 0.9995\n",
    "# estadisticas importantes a tomar en cuenta por episodio\n",
    "# posteriormente se van a mostrar todas las ganancias, el promedio, maximo y minimo \n",
    "# el cumulative reward tambien es importante \n",
    "\n",
    "ganancias = []\n",
    "histories = []\n",
    "actualizacion = 0\n",
    "top_mean = 0\n",
    "save = False\n",
    "\n",
    "# empieza el loop principal, el for es representativo de cada partida, cada iteracion es un nuevo intento\n",
    "for i in range(4000,episodios):\n",
    "    # inicializar las ganancias en 0 para la partida \n",
    "    episode_reward = 0\n",
    "    # inicializar el contador de steps que hay, no necesariamente va a ser un frame \n",
    "    step = 1 \n",
    "    \n",
    "    # primer imagen a utilizar, aqui ya pasa transformada a la necesidad del juego\n",
    "    imagen_actual = np.expand_dims(cv.resize(cv.cvtColor(env.reset(), cv.COLOR_RGB2GRAY),(64,64))[30:50,5:],2)\n",
    "    \n",
    "    # reiniciar la variable done porque obviamente despues de cada partida sera true\n",
    "    done = False \n",
    "    \n",
    "    # este es el loop de la partida, cada iteracion es un step, mientras no haya terminado...\n",
    "    while not done:\n",
    "        \n",
    "        # Exploration vs exploitation, en base al valor de epsilon va a hacer alguna de las 2 \n",
    "        if np.random.random() > epsilon:\n",
    "            # en este caso va a predecir, es decir, explotar el modelo actual \n",
    "            action = predecir_qs(imagen_actual,modelo_prediccion)\n",
    "        else:\n",
    "            # en este caso va a explorar, es decir intentar algo random\n",
    "            action = env.action_space.sample()\n",
    "        \n",
    "        env.render()\n",
    "        # ahora hay que obtener la informacion del step que se esta realizando en base a la accion que predijimos\n",
    "        imagen_nueva, reward, done, exta_info = env.step(action)\n",
    "        # hacer la transformacion adhoc de la imagen \n",
    "        imagen_nueva = np.expand_dims(cv.resize(cv.cvtColor(imagen_nueva, cv.COLOR_RGB2GRAY),(64,64))[30:50,5:],2)\n",
    "        # obtener la recompensa de la accion que acabamos de hacer y sumarselo al acumulador de la partida \n",
    "        episode_reward += reward \n",
    "        \n",
    "        # ingresar al memory replay la imagen actual, la accion que hicimos, el reward, la imagen nueva y si ya termino o no \n",
    "        memory.append((imagen_actual, action, reward, imagen_nueva, done))\n",
    "        # ENTRENAMIENTO, actualizacion es un contador de actualizacion del modelo de target \n",
    "        actualizacion = train(done,actualizacion,save)\n",
    "        \n",
    "        # actualizar la imagen con la nueva que devuelve el step\n",
    "        imagen_actual = imagen_nueva\n",
    "        step += 1 \n",
    "    # al terminar la partida ponemos la suma de las recompensas de todas las acciones a un arreglo para su analisis\n",
    "    ganancias.append(episode_reward)\n",
    "    if np.mean(np.asarray(ganancias)) > top_mean:\n",
    "        top_mean = np.mean(np.asarray(ganancias))\n",
    "        path = \"./ModelosKungFu1/modelo3\" + str(i) + \".h5\"\n",
    "        modelo_prediccion.save(path)\n",
    "        print(\"Mejor modelo guardado en partida #\",str(i))\n",
    "    if i % 500 == 0:\n",
    "        print(\"Episodio #\",str(i))\n",
    "    \n",
    "    # hacer el decay del epsilon para que poco a poco vaya explotando mas al modelo y deje de explorar \n",
    "    if epsilon > 0.1:\n",
    "        epsilon *= decay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cargar el modelo para prueba\n",
    "modelt = load_model('./ModelosExternos/modelo129.h5')\n",
    "opt = keras.optimizers.Adam(learning_rate=0.0001)\n",
    "modelt.compile(optimizer=opt,\n",
    "                  loss='mse',\n",
    "                  metrics=['accuracy'])\n",
    "#modelt.load_weights(\"./ModelosFinales/modelo_prediccion2_weights.h5\")\n",
    "\n",
    "#opt = keras.optimizers.RMSprop(learning_rate=0.00025)\n",
    "#modelt.compile(optimizer=opt,\n",
    "#                 loss='mse',\n",
    "#                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 20, 59, 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.expand_dims(np.expand_dims(cv.resize(cv.cvtColor(env.reset(), cv.COLOR_RGB2GRAY),(64,64))[30:50,5:],2),0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_image = env.reset()\n",
    "for _ in range(1000):\n",
    "    env.render()\n",
    "    next_image = np.expand_dims(np.expand_dims(cv.resize(cv.cvtColor(next_image, cv.COLOR_RGB2GRAY),(64,64))[30:50,5:],2),0)\n",
    "    next_image, reward, done, info = env.step(np.argmax(modelt.predict(next_image)))\n",
    "    if done:\n",
    "        break\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards = pickle.load(open(\"./ModelosFinales/ganancias4.txt\",\"rb\"))\n",
    "x_axis = [i for i in range(len(rewards))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x266791a5948>]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x_axis,rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x266789b5e88>]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "rewards_mean = []\n",
    "means = []\n",
    "maxr = []\n",
    "for i in rewards:\n",
    "    rewards_mean.append(i)\n",
    "    means.append(np.mean(np.array(rewards_mean)))\n",
    "    maxr.append(np.max(np.array(rewards_mean)))\n",
    "plt.plot(x_axis,means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2651f1754c8>]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x_axis,maxr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
